<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>My Fellow Americans... - PolitiNerd</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="/dnc_speeches.html">

        <meta name="author" content="Nick Conti" />
        <meta name="keywords" content="Tutorial,NLP,NLTK,wordcloud,Python" />
        <meta name="description" content="Analyzing National Convention Speeches Using Python and NLTK." />

        <meta property="og:site_name" content="PolitiNerd" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="My Fellow Americans..."/>
        <meta property="og:url" content="/dnc_speeches.html"/>
        <meta property="og:description" content="Analyzing National Convention Speeches Using Python and NLTK."/>
        <meta property="article:published_time" content="2016-08-16" />
            <meta property="article:section" content="Blog" />
            <meta property="article:tag" content="Tutorial" />
            <meta property="article:tag" content="NLP" />
            <meta property="article:tag" content="NLTK" />
            <meta property="article:tag" content="wordcloud" />
            <meta property="article:tag" content="Python" />
            <meta property="article:author" content="Nick Conti" />


    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.flatly.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>





</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
PolitiNerd            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="/pages/about-me.html">
                             About
                          </a></li>
                         <li><a href="/pages/course-list.html">
                             Courses
                          </a></li>
                         <li><a href="/pages/portfolio.html">
                             Portfolio
                          </a></li>
                         <li><a href="/pages/resume.html">
                             Resume
                          </a></li>
                        <li class="active">
                            <a href="/category/blog.html">Blog</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container-fluid">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/dnc_speeches.html"
                       rel="bookmark"
                       title="Permalink to My Fellow Americans...">
                        My Fellow Americans...
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2016-08-16T08:15:00-05:00"> Tue 16 August 2016</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/tutorial.html">Tutorial</a>
        /
	<a href="/tag/nlp.html">NLP</a>
        /
	<a href="/tag/nltk.html">NLTK</a>
        /
	<a href="/tag/wordcloud.html">wordcloud</a>
        /
	<a href="/tag/python.html">Python</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <h1>My Fellow Americans...</h1>
<h2>Analyzing National Convention Speeches Using Python and NLTK</h2>
<p>This is the first post in a series that will examine convention speeches from the RNC and DNC. This post focuses on gathering the speech transcripts, preparing them for analysis, and some initial analysis focused on a sample of DNC speeches. There is a Jupyter notebook available <a href="https://github.com/NickyThreeNames/DNCSpeeches">here</a>. The plan will be to develop a function using a sample speech before downloading and cleaning the data.  Once the function or functions are ready, I will download the all relevant speeches and begin the analysis.</p>
<h3>Getting the transcripts</h3>
<p>There are a lot of sources for transcripts of the speeches, and I wanted one source for all the speeches to create some consistency. Initially, I looked to the websites for the conventions, but the DNC's convention <a href="https://www.demconvention.com/">website</a> lacked transcripts for several speeches. After looking at some news websites, I settled on <a href="http://time.com/">Time Magazine</a>. They had the advantage of (relatively) easily parsed web pages and (most importantly) they were  laid out for consistently for each speech.</p>
<p>Examining the source for the page shows us that all of the transcript is contained within a blockquote tag. That will make this much easier. Using <a href="https://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a> in Python, we can extract the text for the transcript using the following code:</p>
<div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span> 
<span class="n">x</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;blockquote&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
</pre></div>


<p>The above code downloads and parses the HTML in the first two lines and the third line extracts the text from the blockquote tag.  The "[0]" returns the first instance and luckily the speech transcripts are always in the first blockquote tag.  Without the "[0]", we would get a list which would add another step to our extraction. The .get_text() command extracts all the text from the blockquote section we identified Printing out the results shows us the speech text, some HTML junk (like '/n'), punctuation, and "(APPLAUSE)".</p>
<h3>Cleaning the text</h3>
<p>Now that we have the text, let's clean it up. A quick thank you to Kaggle for their <a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words">post</a> on text analysis, this was a really helpful article for guiding me in a lot of this analysis. First I will remove all of the weird punctuation and other symbols using a <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expression</a> via the re <a href="https://docs.python.org/2/library/re.html">package</a>. I am not a regular expression expert, but the following line removes all non-letters from the data.</p>
<div class="highlight"><pre><span></span><span class="n">letters</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;[^a-zA-Z]&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">letters</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>


<p>Now that we have just the letters, we can use .lower() and .split() to break the strings into words that are all lowercase. Putting everything into lowercase ensures that "family" and "Family" both get counted as the same word. Next, I remove stop words and repetitive words that lack a lot of meaning in this context.</p>
<div class="highlight"><pre><span></span><span class="n">stops</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">))</span>
<span class="n">meaningful_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">stops</span><span class="p">]</span>
<span class="n">speech_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;thank&#39;</span><span class="p">,</span> <span class="s1">&#39;you&#39;</span><span class="p">,</span> <span class="s1">&#39;philadelphia&#39;</span><span class="p">,</span> <span class="s1">&#39;applause&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">]</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">meaningful_words</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">speech_words</span><span class="p">]</span>
<span class="k">return</span><span class="p">(</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>


<p>The first line loads stop words from the NLTK package. Stop words are common parts of speech that do not convey much meaning by themselves such as "to", "a", "the". Taking these out allows us to focus on more meaningful words in the analysis. (more info <a href="https://en.wikipedia.org/wiki/Stop_words">here</a>) Additionally, I added words like "thank", "you", and "applause" to a list to be removed. They  appear in every speech and are not adding much to this analysis. Lines two and four  of the code remove the words from the speech if they are listed in either the variable "stops" or "speech_words". The final line joins everything back into a long string. The full function is below.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">speech_parser</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span> 
    <span class="n">x</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;blockquote&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
    <span class="n">letters</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;[^a-zA-Z]&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">letters</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">stops</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">))</span>
    <span class="n">meaningful_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">stops</span><span class="p">]</span>
    <span class="n">speech_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;thank&#39;</span><span class="p">,</span> <span class="s1">&#39;you&#39;</span><span class="p">,</span> <span class="s1">&#39;philadelphia&#39;</span><span class="p">,</span> <span class="s1">&#39;applause&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">]</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">meaningful_words</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">speech_words</span><span class="p">]</span>
    <span class="k">return</span><span class="p">(</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>


<h3>Word clouds!</h3>
<p>While not the most scientific analysis, everybody loves a word cloud. Fortunately members of the Python community created a package, <a href="http://amueller.github.io/word_cloud/">word_cloud</a>, to accomplish this task. We can use the function above to pull the text for one of the speeches and then send it to word cloud.</p>
<div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://time.com/4429984/dnc-hillary-clinton-speech-video-transcript/?iid=sr-link5&#39;</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">speech_parser</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>


<p>The above code parses the website and assigns it to the variable "z". Then I send z over to the word-cloud package.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">750</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="mninteractive" src="/images/wcb.png"></p>
<p>The above code creates the word-cloud with a white background. If you are using a Jupyter notebook, the size parameters in the package will be overridden by the notebook settings. However ".to_file()" can be added to the end of the first line to save the word-cloud to a file. The saved file will use the height and width parameters set in the function. It can be fun/informative to compare the word-clouds between speeches. Compare the above word-cloud with one from Sen. Cory Booker's speech. </p>
<div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://time.com/4421756/democratic-convention-cory-booker-transcript-speech/?iid=sr-link10&#39;</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">speech_parser</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">750</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s1">&#39;wc1.png&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="mninteractive" src="/images/wc2.png">    </p>
<p>There are a lot more customization options in wordcloud. I recommend checking out the documentation for more <a href="http://amueller.github.io/word_cloud/index.html">information</a>.</p>
<h3>Frequent Terms</h3>
<p>Next I'll examine the most frequent terms used in eight of the speeches. I hand selected a list of the speeches focused mainly on the headline speakers. Time's website had really weird search results and I gave up on an automated solution. I used the code below to pull together a list of lists containing the speech transcripts.</p>
<div class="highlight"><pre><span></span><span class="n">speech_list</span> <span class="o">=</span> <span class="p">[</span>
<span class="s1">&#39;http://time.com/4426037/dnc-tim-kaine-speech-transcript-video/?iid=sr-link1&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4426150/dnc-barack-obama-transcript/&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4429984/dnc-hillary-clinton-speech-video-transcript/?iid=sr-link5&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4421538/democratic-convention-michelle-obama-transcript/?iid=sr-link1&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4421574/democratic-convention-bernie-sanders-speech-transcript/?iid=sr-link3&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4425599/dnc-bill-clinton-speech-transcript-video/?iid=sr-link2&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4426178/dnc-joe-biden-speech-transcript-video/?iid=sr-link7&#39;</span><span class="p">,</span>
<span class="s1">&#39;http://time.com/4421756/democratic-convention-cory-booker-transcript-speech/?iid=sr-link10&#39;</span><span class="p">]</span>

<span class="n">speeches</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">speech_list</span><span class="p">:</span>
    <span class="n">speeches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">speech_parser</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</pre></div>


<p>This code gives a lists within the speeches list for each of the eight speakers. We will analyze the most common and most interesting (defined very loosely) words within each speech. The speakers are Tim Kaine, President Obama, Hillary Clinton, Bernie Sanders, Michelle Obama, Bill Clinton, Joe Biden, and Cory Booker. Each speech is in its own list within the speeches list. First I will generate a list of the 5 most common terms in each speech using <a href="http://scikit-learn.org/stable/">Scikit-learn's</a> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">Count Vectorizer</a>. The count vectorizer will not only count each word, but also will split our long text strings into individual words. I could have done this in the earlier scraping function, but that would have caused issues for the word-cloud package. </p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">speeches</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>


<p>The above code generates a sparse matrix with each word, their respective counts for each speech, and converts the matrix to an array (for processing speed later). Rather than try to read this giant table, I will use the following code to print out the five top words for each speech. Thank you to <a href="http://stackoverflow.com">Stack Overflow</a> for the <a href="http://stackoverflow.com/questions/28619595/how-to-get-top-terms-based-on-tf-idf-python">code</a> used below.</p>
<div class="highlight"><pre><span></span><span class="n">fn1</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span> 
    <span class="k">print</span><span class="p">([(</span><span class="n">fn1</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">l</span><span class="o">*-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()][:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>


<p>The above code sorts the array and prints out the top five terms for each speech. You can easily modify the code above to print any number of terms. Each speech will appear in a separate list in the order they were saved by the speech_parser function. I have manually created the table below that shows each term's count.</p>
<table>
<thead>
<tr>
<th>Speaker</th>
<th>Terms</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kaine</td>
<td>'trump', 'donald', 'believe', 'kaine', 'ready'</td>
</tr>
<tr>
<td>Pres. Obama</td>
<td>'america', 'hillary', 'people', 'every', 'years'</td>
</tr>
<tr>
<td>Hillary Clinton</td>
<td>'people', 'us', 'america', 'country', 'know'</td>
</tr>
<tr>
<td>Michelle Obama</td>
<td>'cheers', 'hillary', 'president', 'every', 'kids'</td>
</tr>
<tr>
<td>Sanders</td>
<td>'election', 'clinton', 'hillary', 'people', 'country'</td>
</tr>
<tr>
<td>Bill Clinton</td>
<td>'class', 'enough', 'political', 'tap', 'intending'</td>
</tr>
<tr>
<td>Biden</td>
<td>'know', 'hillary', 'america', 'always', 'never'</td>
</tr>
<tr>
<td>Booker</td>
<td>'nation', 'america', 'americans', 'us', 'love'</td>
</tr>
</tbody>
</table>
<p>No surprising results there. I do like how a lot of Bill Clinton's speech mentioned phrases about meeting/dating Hillary. The count vectorizer function has a lot of additional options I am not using in this example. Most notably it lets you use n-grams (groups of words appearing in a row of n length). I had tried this but ended up with a lot of repetitive results like 'Hillary', 'Clinton', 'Hillary Clinton', etc. While the results are interesting, we can also leverage more of sikit-learn's text processing features to look at the most unique words in each speech using TF-IDF.</p>
<p>TF-IDF is term document inverse document frequency. Basically, it is the number of times a word appears in a document (or speech in this case) divided by the number of times it appears in all documents. An exhaustive amount of detail is available at this Wikipedia <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">article</a>. Basically, words that are more unique to a given speech will get a higher score. This should reduce the repetition of words between speeches.</p>
<div class="highlight"><pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">speeches_tfidf</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>


<p>This code, like before, creates a sparse matrix of terms with their TF-IDF score in place of their raw count. Again, this package has more options, like n-grams, that I will not be diving into in this tutorial. Below is code to print out the top eight words for each speech based on their TF-IDF score.</p>
<div class="highlight"><pre><span></span><span class="n">mat_array</span> <span class="o">=</span> <span class="n">speeches_tfidf</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">fn</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>

<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">mat_array</span><span class="p">:</span> 
    <span class="k">print</span><span class="p">([(</span><span class="n">fn</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">l</span><span class="o">*-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()][:</span><span class="mi">8</span><span class="p">])</span>
</pre></div>


<p>Thanks again to Stack Overflow for the code for this printing this out. I have manually recreated the table below.</p>
<table>
<thead>
<tr>
<th>Speaker</th>
<th>Terms</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kaine</td>
<td>'trump', 'ready', 'donald', 'believe', 'puede', 'se', 'si', 'kaine'</td>
</tr>
<tr>
<td>Pres. Obama</td>
<td>'america', 'hillary', 'every', 'people', 'years', 'better', 'still', 'know'</td>
</tr>
<tr>
<td>Hillary Clinton</td>
<td>'people', 'us', 'america', 'country', 'working', 'trump', 'know', 'believe'</td>
</tr>
<tr>
<td>Michelle Obama</td>
<td>'cheers', 'every', 'kids', 'hillary', 'president', 'country', 'children', 'girls'</td>
</tr>
<tr>
<td>Sanders</td>
<td>'election', 'clinton', 'hillary', 'people', 'country', 'campaign', 'percent', 'americans'</td>
</tr>
<tr>
<td>Bill Clinton</td>
<td>'enough', 'tap', 'appropriately', 'thick', 'spring', 'glasses', 'introduce', 'magnetic'</td>
</tr>
<tr>
<td>Biden</td>
<td>'know', 'jill', 'always', 'mean', 'hillary', 'america', 'say', 'folks'</td>
</tr>
<tr>
<td>Booker</td>
<td>'nation', 'america', 'americans', 'rise', 'history', 'us', 'love', 'people'</td>
</tr>
</tbody>
</table>
<p>This has more insight. I especially enjoy Pres. Bill Clinton's terms 'glasses' and 'magnetic'. He spoke a lot about him and Hillary when they were younger and you can see that come through in the TF-IDF terms.  The above code can be modified to show more terms, and could give more insights into the topics discussed. While it does a better job at finding interesting trends, TF-IDF can occasionally yield some weird results so be sure to take a close look at the results. Additionally, it falls into the same trap mentioned above with repetitive/redundant phrases, but does a much better job than raw counts.</p>
<p>There are some additional text processing steps beyond the scope of this example. Stemming can be applied to words to reduce redundancy by transforming words like  'runs' and 'running' into 'run'. Additionally, we can add n-grams to the analysis as I mentioned earlier. I will plan to cover some of these additional topics in the future.</p>
<p>In the next installment on convention speeches, I will look at some speeches from the RNC and introduce topic modeling. Can we identify common topics within the speeches? Do the topics differ from what was spoken about at the DNC? (hint, they do).</p>
            </div>
            <!-- /.entry-content -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'politinerd'; // required: replace example with your forum shortname

                    var disqus_identifier = 'dnc_speeches';
                var disqus_url = '/dnc_speeches.html';

            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<div id="aboutme">
        <p>
            <img width="100%" class="img-thumbnail" src="/../images/me.png"/>
        </p>
    <p>
      <strong>About Nick Conti</strong><br/>
        
I am a data analyst living in Minneapolis.
<br></br>
Though I work in banking now, I had my come-up working in political campaign data, beginning as a field organizer and eventually becoming a Statewide Data Director in Michigan.  I spent a lot of my time <del> fighting</del> working with Excel but became annoyed with its limitations as I focused more on data analysis.  Somewhere along the line, I was introduced to R, then Python, and the rest is history.  It was an instant nerd crush and I have been expanding my data programming skills since.  This blog is my valentine to the possibilities of what can be accomplished with data.
<br></br>
When not dealing with numbers, I can be found running, biking, and enjoying a beer on a patio.
 
    </p>
</div><!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/NickyThreeNames"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
    <li class="list-group-item"><a href="https://www.linkedin.com/in/nick-conti-6364475"><i class="fa fa-linkedin-square fa-lg"></i> LinkedIn</a></li>
    <li class="list-group-item"><a href="https://twitter.com/nickythreenames"><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-4">
      <a href="/tag/about.html">About</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/api.html">api</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/class.html">Class</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/congress.html">Congress</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/election.html">Election</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/elections.html">elections</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/fec.html">FEC</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/folium.html">Folium</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gis.html">GIS</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/leaflet.html">Leaflet</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/machine-learning.html">Machine Learning</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/map.html">map</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/mnhouse.html">MNHouse</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/nlp.html">NLP</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/nltk.html">NLTK</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/python.html">Python</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/r.html">R</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/review.html">Review</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/social-media.html">Social Media</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/strategy.html">Strategy</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/targeting.html">Targeting</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/tutorial.html">Tutorial</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/twitter.html">Twitter</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/wordcloud.html">wordcloud</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://getpelican.com" target="_blank">Pelican</a>
    </li>
    <li class="list-group-item">
      <a href="http://fivethirtyeight.com" target="_blank">FiveThirtyEight</a>
    </li>
    <li class="list-group-item">
      <a href="http://realpython.com" target="_blank">RealPython</a>
    </li>
    <li class="list-group-item">
      <a href="https://www.yhat.com" target="_blank">Yhat</a>
    </li>
    <li class="list-group-item">
      <a href="http://www.r-bloggers.com" target="_blank">R-bloggers</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container-fluid">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 Nick Conti
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>

    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'politinerd'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->


</body>
</html>