<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>It's Alive! The Frankenstein Method of Building Candidate Support Models - PolitiNerd</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="/candidate_models.html">

        <meta name="author" content="Nick Conti" />
        <meta name="keywords" content="Targeting,Python,Machine Learning" />
        <meta name="description" content="Strategies for creating candidate support models." />

        <meta property="og:site_name" content="PolitiNerd" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="It&#39;s Alive! The Frankenstein Method of Building Candidate Support Models"/>
        <meta property="og:url" content="/candidate_models.html"/>
        <meta property="og:description" content="Strategies for creating candidate support models."/>
        <meta property="article:published_time" content="2017-08-08" />
            <meta property="article:section" content="Blog" />
            <meta property="article:tag" content="Targeting" />
            <meta property="article:tag" content="Python" />
            <meta property="article:tag" content="Machine Learning" />
            <meta property="article:author" content="Nick Conti" />


    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.flatly.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>





</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
PolitiNerd            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="/pages/about-me.html">
                             About
                          </a></li>
                         <li><a href="/pages/course-list.html">
                             Courses
                          </a></li>
                         <li><a href="/pages/portfolio.html">
                             Portfolio
                          </a></li>
                         <li><a href="/pages/resume.html">
                             Resume
                          </a></li>
                        <li class="active">
                            <a href="/category/blog.html">Blog</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container-fluid">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/candidate_models.html"
                       rel="bookmark"
                       title="Permalink to It's Alive! The Frankenstein Method of Building Candidate Support Models">
                        It's Alive! The Frankenstein Method of Building Candidate Support Models
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2017-08-08T09:15:00-05:00"> Tue 08 August 2017</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/targeting.html">Targeting</a>
        /
	<a href="/tag/python.html">Python</a>
        /
	<a href="/tag/machine-learning.html">Machine Learning</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <h1>Building Candidate Support Models with Ensembles - The Frankenstein Method</h1>
<p><img alt="youngfrankenstein" src="/images/youngfrankenstein.jpg"></p>
<p>Having a model to predict a voters likelihood to support your candidate is the backbone of a campaign's data operation. Combined with voter turnout models, you can more effectively plan your strategy, allocate resources, and contact the right voters at the right time. There is a fine art to building these models but instead of focusing on that, I will walk through one strategy of cobbling together several simpler models. Basically it's the kitchen sink or Frankenstein's monster approach to machine learning. Unlike in the preivous <a href="http://www.nickconti.io/partisan_model.html">post</a>, there will not be any parameter tuning; I will instead use the defaut paratmeters of all of the models. Then I will then walk through a few methods of how to combine them into a well rounded model to predict which voters are likely to support your candidate.</p>
<h3>Getting the IDs</h3>
<p>I am using the same data as before, industry grade voter file with commercial enhancements that has actual candidate IDs appended. In a regular campaign, there would be a lot of effort needed to call voters (either with volunteers or vendors) to ask who they are supporting. Once we have enough IDs for the candidates in our election, we can use them to build a model to predict how the rest of the voters are likely to feel. This is not an exact science however. I know that using data and models in elections is out of favor right now in the press, but a well made (and more importantly well applied) model is still essential to a campaign. While they cannot be the only consideration in campaign strategy, they can give a great insight into which groups of voters need more outreach, and how best to engage them.</p>
<p>Traditionally, campaigns will use a 5 point scale for identifying support 1-Strong Supporter, 2-Lean Supporters, 3-Undecided, 4-Lean Opponent, 5-Strong Opponent. When building the model you will need to decide what it is you are modeling. In our case, this is who is a 1 or a 2 versus all of the rest. For these models a score of 100 is as confident as we can be that the voter in question is a supporter, while a 0 is a very confident estimate they really do not support our candidate. NOTE - a middle score does not mean that the voter is undecided! It means the model is undecided on whether they are likely to be a supporter, not that the voter is undecided. Unless the model is specifically built to find undecided voters, do not make this mistake. This is a common mistake made by a lot of experienced professionals. While mid-scoring voters is still a potentially useful group to call for IDs, it does not mean they are undecided or persuadable. You can specifically model whether they are undecided but cannot assume that is part of all candidate models.</p>
<p>As I mentioned, I will use both 1s and 2s as supporters for this model. In this case decision is arbirtrary, but you should decide what makes the most sense in a specific race. As in the last <a href="http://www.nickconti.io/partisan_model.html">post</a>, I will remove columns that are derived or informed by the results of the ID so we do not use data from IDs we have not done yet. Below is code to look at the counts of each ID and produce a histogram.</p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;CAND1_LD2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>


<p><img alt="histogram" src="/images/classImbalance.PNG"></p>
<p>The next step is to split the data into a training set and a test set. The test_size parameter takes a percentage of observations to move to a test set and automatically shuffles and splits. In this case we will keep 1/3 of the data for a test set.</p>
<div class="highlight"><pre><span></span><span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)</span>
<span class="n">X</span><span class="o">=</span><span class="n">data1</span>

<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.33</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">55</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</pre></div>


<p>Since many classifiers are sensitive to outliers and larger numeric values (such as logistic regression), I  run everything through the scikit learn <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">standard scaler</a>. In the previous post I had put this step in a pipeline. This time I am using it separately since I am creating several separate models.</p>
<div class="highlight"><pre><span></span><span class="n">ssc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="n">X_train1</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test1</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>


<p>Since the data is imbalanced, using stratified k fold will balance the data used during cross validation to give a more helpful measure of the accuracy. By balancing the classes, the model will be tested equally on both 1's and 0's and eliminates the risk that a test will have just one class in it.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="n">cv1</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>


<p>Next, I create a list of three models (Naive Bayes, Random Forest, and Linear Discriminant Analysis)  with no parameter tuning to blend together later. Each is appended with a label for use later. I also set the class weight parameter to balanced, when available, to help offset the class imbalance.</p>
<div class="highlight"><pre><span></span><span class="n">estimators1</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">model1</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span> 
<span class="n">estimators1</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;nb&#39;</span><span class="p">,</span> <span class="n">model1</span><span class="p">))</span>

<span class="n">model2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">class_weight</span> <span class="o">=</span> <span class="s1">&#39;balanced&#39;</span><span class="p">)</span> 
<span class="n">estimators1</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">model2</span><span class="p">))</span>

<span class="n">model3</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span>
<span class="n">estimators1</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;lda&#39;</span><span class="p">,</span> <span class="n">model3</span><span class="p">))</span>
</pre></div>


<p><img alt="accuracies" src="/images/accuracies.PNG"></p>
<p>The first method of blending is to have each model vote on which class (supporter or not) to assign each voter. The code also prints out the accuracy of each individual model and the accuracy for blended model. (<a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html">Link</a> for more info)</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">estimators1</span><span class="p">:</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">ensembles</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators1</span><span class="p">)</span> 
<span class="n">results</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">results</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>


<p><img alt="acc2" src="/images/votingAcc.PNG"></p>
<p>As I hoped, the voting model is more accurate overall than each of the models individually. I, for whatever really nerdy reason, find this a fascinating part of machine learning. Each model balances out flaws in the other models to create a more accurate prediction. Below, I  create a plot that shows how many people were assigned each label versus what the test data said their label was. Correct answers have the same label (so boxes 0,0 and 1,1). Each cell is shaded based on how many observations fall into each category. There is a chart for each indidvidual model and then the voting ensemble.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlxtend.plotting</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">lab</span><span class="p">,</span> <span class="n">grd</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">,</span> <span class="n">model3</span><span class="p">,</span> <span class="n">ensembles</span><span class="p">],</span> 
                     <span class="p">[</span><span class="s1">&#39;NB&#39;</span><span class="p">,</span> 
                      <span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> 
                      <span class="s1">&#39;LDA&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;Ensemble&#39;</span>
                      <span class="p">],</span>
                      <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">)):</span>

    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
    <span class="c1">#ax = plt.subplot(gs[grd[0], grd[1]])</span>
    <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">conf_mat</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">lab</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="confMatrix" src="/images/confMatrix.PNG"></p>
<p>In the first chart you can see the Naive Bayes classifier is doing well overall while the Random Forest is very accurately classifying the 0's but struggling with the 1's. The LDA model does a surprisingly good job with the highest accuracy but the blended model balance between precision and recall. Basically, it predicts both classes better than each of the individual models.</p>
<p>Next is a stacking model where a meta-model is fit on top of the results from other models. Mlxtend has two useful functions for creating this model, StackingClassifier and <a href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/">StackingCVClassifier</a>. The second is shown below.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlxtend.classifier</span> <span class="kn">import</span> <span class="n">StackingCVClassifier</span>

<span class="n">m1</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">m2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">class_weight</span> <span class="o">=</span> <span class="s1">&#39;balanced&#39;</span><span class="p">)</span>
<span class="n">m3</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span> <span class="o">=</span> <span class="s1">&#39;balanced&#39;</span><span class="p">)</span>

<span class="n">sclf2</span> <span class="o">=</span> <span class="n">StackingCVClassifier</span><span class="p">(</span><span class="n">classifiers</span><span class="o">=</span><span class="p">[</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m3</span><span class="p">],</span> 
                      <span class="n">meta_classifier</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> 
                        <span class="n">use_probas</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv1</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">sclf2</span><span class="p">,</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>


<p><img alt="confMatrix2" src="/images/confMatrix2.PNG"></p>
<p>The code above fits the same three models from before and then uses their predictions as input for the final logistic regression model. The function also takes care of splitting the training data between the three models and the final meta-model as well as the splits needed for cross-validation. These are all fit using the same cross-validation setup as before so that comparing performance is easier. Below is a confusion matrix to evaluate the performance.</p>
<p>As with the Voting Classifier, this model has great balance in predicting both classes accurately. It does slightly better than the voting ensemble, but both are surprisingly accurate.</p>
<p>The StackingClassifier model has additional options worth exploring whether to include the "use_proba" which uses probability estimates from the base models as input. Also, you can tune parameters (using cross-validation) on the input models and/or the meta model. But those are topics for a future post, but you can learn more <a href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/">here</a> in the meantime. </p>
<p>Using the methods outlined above, you can quickly evaluate the performance of several models (possibly for use later) as well as blend together their predictions . This is a common step in a manchine learning workflow and can be used in a variety of predictive modeling tasks.</p>
            </div>
            <!-- /.entry-content -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'politinerd'; // required: replace example with your forum shortname

                    var disqus_identifier = 'candidate_models';
                var disqus_url = '/candidate_models.html';

            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<div id="aboutme">
        <p>
            <img width="100%" class="img-thumbnail" src="/../images/me.png"/>
        </p>
    <p>
      <strong>About Nick Conti</strong><br/>
        
I am a data analyst living in Minneapolis.
<br></br>
Though I work in banking now, I had my come-up working in political campaign data, beginning as a field organizer and eventually becoming a Statewide Data Director in Michigan.  I spent a lot of my time <del> fighting</del> working with Excel but became annoyed with its limitations as I focused more on data analysis.  Somewhere along the line, I was introduced to R, then Python, and the rest is history.  It was an instant nerd crush and I have been expanding my data programming skills since.  This blog is my valentine to the possibilities of what can be accomplished with data.
<br></br>
When not dealing with numbers, I can be found running, biking, and enjoying a beer on a patio.
 
    </p>
</div><!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/NickyThreeNames"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
    <li class="list-group-item"><a href="https://www.linkedin.com/in/nick-conti-6364475"><i class="fa fa-linkedin-square fa-lg"></i> LinkedIn</a></li>
    <li class="list-group-item"><a href="https://twitter.com/nickythreenames"><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-4">
      <a href="/tag/about.html">About</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/api.html">api</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/class.html">Class</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/congress.html">Congress</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/election.html">Election</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/elections.html">elections</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/fec.html">FEC</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/folium.html">Folium</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gis.html">GIS</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/leaflet.html">Leaflet</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/machine-learning.html">Machine Learning</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/map.html">map</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/mnhouse.html">MNHouse</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/nlp.html">NLP</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/nltk.html">NLTK</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/python.html">Python</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/r.html">R</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/review.html">Review</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/targeting.html">Targeting</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/tutorial.html">Tutorial</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/wordcloud.html">wordcloud</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://getpelican.com" target="_blank">Pelican</a>
    </li>
    <li class="list-group-item">
      <a href="http://fivethirtyeight.com" target="_blank">FiveThirtyEight</a>
    </li>
    <li class="list-group-item">
      <a href="http://realpython.com" target="_blank">RealPython</a>
    </li>
    <li class="list-group-item">
      <a href="https://www.yhat.com" target="_blank">Yhat</a>
    </li>
    <li class="list-group-item">
      <a href="http://www.r-bloggers.com" target="_blank">R-bloggers</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container-fluid">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 Nick Conti
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>

    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'politinerd'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->


</body>
</html>